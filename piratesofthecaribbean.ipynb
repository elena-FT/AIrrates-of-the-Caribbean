{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### FOUILLET Elena / HARTMANN Louise","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport shutil\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-28T17:56:19.659693Z","iopub.execute_input":"2023-05-28T17:56:19.660128Z","iopub.status.idle":"2023-05-28T17:56:19.667681Z","shell.execute_reply.started":"2023-05-28T17:56:19.660086Z","shell.execute_reply":"2023-05-28T17:56:19.666291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Récupération et affichages des données ","metadata":{}},{"cell_type":"code","source":"# Liste des catégories de bateaux\ncategories = [\n    \"coastguard_scaled\",\n    \"containership_scaled\",\n    \"corvette_scaled\",\n    \"cruiser_scaled\",\n    \"cv_scaled\",\n    \"destroyer_scaled\",\n    \"methanier_scaled\",\n    \"smallfish_scaled\",\n    \"submarine_scaled\",\n    \"tug_scaled\"\n]","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:19.670777Z","iopub.execute_input":"2023-05-28T17:56:19.671181Z","iopub.status.idle":"2023-05-28T17:56:19.678324Z","shell.execute_reply.started":"2023-05-28T17:56:19.671140Z","shell.execute_reply":"2023-05-28T17:56:19.677004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Avant de nous plonger dans le défi de la détection du type de bateau à partir d'images, il est essentiel de passer par une étape cruciale : le prétraitement des données. Cette étape revêt une grande importance dans la construction d'un réseau de neurones performant.\n\nNos données consistent en un ensemble d'images de bateaux, chacune ayant une taille de 16x24 pixels. Ces images peuvent contenir des variations de couleurs, de luminosité, de rotation et d'autres facteurs qui peuvent impacter la capacité de notre modèle à apprendre des caractéristiques discriminantes.\n\nDans le cadre du prétraitement des données, nous allons appliquer différentes techniques pour améliorer la qualité et la pertinence de nos images. Cela peut inclure des opérations telles que l'ajustement de la luminosité, le contraste, la netteté, la rotation, la mise à l'échelle, etc.\n\nEn visualisant ces images, nous pourrons mieux comprendre la diversité et les défis potentiels associés à notre ensemble de données. Cela nous permettra également de nous familiariser avec les différents types de bateaux présents dans nos images, ce qui sera utile lors de l'analyse des performances de notre modèle par la suite.\n\nPassons maintenant à l'affichage de ces images, afin de pouvoir les observer et en apprendre davantage sur notre ensemble de données.","metadata":{}},{"cell_type":"code","source":"#Afficher les images de bateaux\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nsize_img = (16,24)\n\npath = \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data/\"\nfig = plt.figure(figsize=(15, 7))\nfor i, category in enumerate(categories):\n    category_dir = os.path.join(path, category)\n    image_file = os.listdir(category_dir)\n    img = Image.open(path + category + '/' + image_file[0])\n    fig.add_subplot(3, 4, i + 1)\n    plt.axis('off')\n    plt.imshow(img)\n    plt.title(category) ","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:19.685337Z","iopub.execute_input":"2023-05-28T17:56:19.685782Z","iopub.status.idle":"2023-05-28T17:56:20.366944Z","shell.execute_reply.started":"2023-05-28T17:56:19.685745Z","shell.execute_reply":"2023-05-28T17:56:20.360538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous avons affiché une image représentant chaque type de bateau. Cependant, il est difficile de déterminer visuellement le type de bateau en raison du flou des images. Pour améliorer la netteté de ces photos, nous allons essayer de les ajuster grâce à la méthode de LaPlace.","metadata":{}},{"cell_type":"code","source":"#Afficher les images de bateaux\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom scipy.ndimage import laplace\n\nsize_img = (16,24)\nsharp_filter = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\ninput_dir = \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data/\"\nfig = plt.figure(figsize=(15, 7))\nfor i, category in enumerate(categories):\n    category_dir = os.path.join(input_dir, category)\n    image_file = os.listdir(category_dir)\n    img_path = os.path.join(category_dir, image_file[0])\n    \n    img_normal = Image.open(img_path)\n    img_array = np.array(img_normal)\n    sharpened_array = img_array + laplace(img_array)\n    \n    fig.add_subplot(3, 4, i + 1)\n    plt.axis('off')\n    plt.imshow(sharpened_array)\n    plt.title(category) ","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:20.369183Z","iopub.execute_input":"2023-05-28T17:56:20.369960Z","iopub.status.idle":"2023-05-28T17:56:21.136094Z","shell.execute_reply.started":"2023-05-28T17:56:20.369900Z","shell.execute_reply":"2023-05-28T17:56:21.134902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Malheureusement, les ajustements effectués n'ont pas réussi à rendre les images plus nettes. Nous devons donc essayer une autre approche pour améliorer la qualité des données.","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\n\nsize_img = (16, 24)\nsharp_filter = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n\npath = \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data/\"\nfig = plt.figure(figsize=(15, 7))\n\nfor i, category in enumerate(categories):\n    category_dir = os.path.join(input_dir, category)\n    image_file = os.listdir(category_dir)\n    img_path = os.path.join(category_dir, image_file[0])\n    \n    img_normal = Image.open(img_path)\n    img_array = np.array(img_normal)\n    \n    # Appliquer le filtre de netteté en utilisant la convolution\n    sharpened_array = cv2.filter2D(img_array, -1, sharp_filter)\n    \n    fig.add_subplot(3, 4, i + 1)\n    plt.axis('off')\n    plt.imshow(sharpened_array)\n    plt.title(category)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:21.141766Z","iopub.execute_input":"2023-05-28T17:56:21.142445Z","iopub.status.idle":"2023-05-28T17:56:21.651914Z","shell.execute_reply.started":"2023-05-28T17:56:21.142390Z","shell.execute_reply":"2023-05-28T17:56:21.650853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Malgré les tentatives précédentes, nous constatons que les images ne sont pas significativement plus nettes. Nous devons donc trouver une autre méthode ou une combinaison d'ajustements pour améliorer la netteté des images et rendre les détails plus visibles.","metadata":{}},{"cell_type":"code","source":"from PIL import Image, ImageEnhance\n\nsize_img = (240, 160)  # Nouvelle taille des images agrandies\n\npath = \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data/\"\nfig = plt.figure(figsize=(15, 7))\n\nfor i, category in enumerate(categories):\n    category_dir = os.path.join(input_dir, category)\n    image_file = os.listdir(category_dir)\n    img_path = os.path.join(category_dir, image_file[0])\n    \n    img_normal = Image.open(img_path)\n    \n    # Redimensionner l'image en utilisant l'interpolation\n    img_resized = img_normal.resize(size_img, Image.LANCZOS)\n    \n    enhancer = ImageEnhance.Sharpness(img_resized)\n    img_enhanced = enhancer.enhance(2.0)\n    \n    fig.add_subplot(3, 4, i + 1)\n    plt.axis('off')\n    plt.imshow(img_enhanced)\n    plt.title(category)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:21.654891Z","iopub.execute_input":"2023-05-28T17:56:21.656040Z","iopub.status.idle":"2023-05-28T17:56:22.342472Z","shell.execute_reply.started":"2023-05-28T17:56:21.655995Z","shell.execute_reply":"2023-05-28T17:56:22.341397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En utilisant une approche de redimensionnement des images avec un facteur d'agrandissement de 10 et en appliquant des techniques pour améliorer la netteté, nous avons réussi à obtenir des résultats plus satisfaisants. Les images agrandies et améliorées ont permis de rendre les détails plus visibles et d'améliorer la qualité générale des données.","metadata":{}},{"cell_type":"markdown","source":"Nous allons procéder à la division de nos données en deux dossiers distincts, à savoir \"train\" et \"validation\", en respectant une répartition de 80% pour l'entraînement et 20% pour la validation. Cela nous permettra d'obtenir deux ensembles de données distincts pour ces deux étapes essentielles de notre processus.","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Répartition des données","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Chemin du répertoire à supprimer\ndirectory = '/kaggle/working/'\n\nfor root, dirs, files in os.walk(directory):\n    for file in files:\n        file_path = os.path.join(root, file)\n        os.remove(file_path)\n    for dir in dirs:\n        dir_path = os.path.join(root, dir)\n        shutil.rmtree(dir_path)\nprint(\"Tous les dossiers et fichiers ont été supprimés.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:22.344017Z","iopub.execute_input":"2023-05-28T17:56:22.345231Z","iopub.status.idle":"2023-05-28T17:56:22.403411Z","shell.execute_reply.started":"2023-05-28T17:56:22.345184Z","shell.execute_reply":"2023-05-28T17:56:22.402297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chemins d'accès aux répertoires\ninput_dir = \"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data\"\noutput_dir = \"/kaggle/working/ships\"\ntrain_dir = os.path.join(output_dir, \"train\")\nval_dir = os.path.join(output_dir, \"validation\")\ntest_dir = os.path.join(output_dir, \"test\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:22.405206Z","iopub.execute_input":"2023-05-28T17:56:22.406720Z","iopub.status.idle":"2023-05-28T17:56:22.413877Z","shell.execute_reply.started":"2023-05-28T17:56:22.406676Z","shell.execute_reply":"2023-05-28T17:56:22.412542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Création des répertoires de destination\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(val_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:22.416268Z","iopub.execute_input":"2023-05-28T17:56:22.416885Z","iopub.status.idle":"2023-05-28T17:56:22.425991Z","shell.execute_reply.started":"2023-05-28T17:56:22.416841Z","shell.execute_reply":"2023-05-28T17:56:22.424451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_percentage = 0.8\nval_percentage = 0.2","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:22.428302Z","iopub.execute_input":"2023-05-28T17:56:22.429880Z","iopub.status.idle":"2023-05-28T17:56:22.435247Z","shell.execute_reply.started":"2023-05-28T17:56:22.429824Z","shell.execute_reply":"2023-05-28T17:56:22.433817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Déplacement des images vers les répertoires de destination\nfor category in categories:\n    category_dir = os.path.join(input_dir, category)\n    image_files = os.listdir(category_dir)\n    \n    for file in image_files:\n        source_path = os.path.join(category_dir, file)\n        \n        if np.random.uniform() < train_percentage:\n            dest_dir = os.path.join(train_dir, category)\n        else:\n            dest_dir = os.path.join(val_dir, category)\n        \n        os.makedirs(dest_dir, exist_ok=True)  # Créer le répertoire de destination s'il n'existe pas déjà\n        \n        destination_path = os.path.join(dest_dir, file)\n        shutil.copyfile(source_path, destination_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:22.437359Z","iopub.execute_input":"2023-05-28T17:56:22.438617Z","iopub.status.idle":"2023-05-28T17:56:34.714830Z","shell.execute_reply.started":"2023-05-28T17:56:22.438575Z","shell.execute_reply":"2023-05-28T17:56:34.711506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.2 Pré-traitement des images de train","metadata":{}},{"cell_type":"markdown","source":"Pour améliorer la capacité de notre réseau à interpréter les images, nous allons commencer par les agrandir. En augmentant la taille des images, nous permettons au réseau de neurones de capturer plus de détails et de mieux discerner les caractéristiques distinctives des bateaux. Cela facilitera ainsi la tâche de classification pour notre réseau.","metadata":{}},{"cell_type":"code","source":"#train_dir = \"/kaggle/working/ships/train\"\n\n# Parcourir les sous-dossiers\n#for categorie in categories:\n    # Chemin complet du sous-dossier\n    #categorie_path = os.path.join(train_dir, categorie)\n    \n    # Liste des fichiers dans le sous-dossier\n    #files = os.listdir(categorie_path)\n    \n    # Parcourir les fichiers\n    #for file in files:\n        # Chemin complet du fichier\n        #file_path = os.path.join(categorie_path, file)\n        \n        # Ouvrir l'image avec PIL\n        #image = Image.open(file_path)\n        \n        # Redimensionner l'image\n        #resized_image = image.resize((240, 160))\n        \n        # Écraser l'image d'origine avec l'image redimensionnée\n        #resized_image.save(file_path)\n\n#print(\"Redimensionnement terminé.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.716071Z","iopub.status.idle":"2023-05-28T17:56:34.720268Z","shell.execute_reply.started":"2023-05-28T17:56:34.720048Z","shell.execute_reply":"2023-05-28T17:56:34.720071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensuite, nous allons appliquer un filtre de netteté afin de diversifier notre jeu de données et d'améliorer la robustesse de notre modèle :\n\n- **Netteté** : Pour améliorer la netteté des images, nous allons appliquer une technique de renforcement des contours. Cela permettra de rendre les contours des bateaux plus prononcés et de mieux mettre en évidence les détails importants.\n\nNous espérons augmenter la diversité de notre jeu de données et permettre à notre modèle de mieux généraliser et de détecter efficacement le type de bateau présent dans les images.","metadata":{}},{"cell_type":"code","source":"import random\nfrom PIL import ImageEnhance\nfrom scipy.ndimage.filters import laplace\n\n# Parcourir les sous-dossiers\nfor categorie in categories:\n    categorie_path = os.path.join(train_dir, categorie)\n    \n    files = os.listdir(categorie_path)\n    \n    for file in files:\n        file_path = os.path.join(categorie_path, file)\n        \n        image = Image.open(file_path)\n        \n        for i in range(1):\n            # Améliorer la netteté\n            enhancer = ImageEnhance.Sharpness(image)\n            img_enhanced = enhancer.enhance(2.0)\n\n            output_filename = f\"augmented_{i}_{file}\"\n            output_path = os.path.join(categorie_path, output_filename)\n            \n            # Enregistrer l'image augmentée\n            img_enhanced.save(output_path)\n            \n            # Afficher l'image\n            #plt.imshow(img_enhanced)\n            #plt.axis('off')\n            #plt.title(f\"Augmented Image {i+1}\")\n            #plt.show()\n\nprint(\"Augmentation des données terminée.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.721939Z","iopub.status.idle":"2023-05-28T17:56:34.722555Z","shell.execute_reply.started":"2023-05-28T17:56:34.722262Z","shell.execute_reply":"2023-05-28T17:56:34.722290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_files(folder_path):\n    count = 0\n    \n    for root, dirs, files in os.walk(folder_path):\n        count += len(files)\n    \n    return count\n\ninput_folder = \"/kaggle/working/ships/train\"\n\ntotal_files = count_files(input_folder)\nprint(f\"Nombre total de fichiers : {total_files}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.724774Z","iopub.status.idle":"2023-05-28T17:56:34.725309Z","shell.execute_reply.started":"2023-05-28T17:56:34.725035Z","shell.execute_reply":"2023-05-28T17:56:34.725063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous avons augmenté notre jeu de données initial en créant de nouvelles images. Affichons ces nouvelles images.","metadata":{}},{"cell_type":"code","source":"import os\n\ndirectory = \"/kaggle/working/ships/train/submarine_scaled\"\n\nfiles = os.listdir(directory)\nfor i, filename in enumerate(files[:2]):\n    file_path = os.path.join(directory, filename)\n    \n    if os.path.isfile(file_path):\n        print(filename)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.727508Z","iopub.status.idle":"2023-05-28T17:56:34.728022Z","shell.execute_reply.started":"2023-05-28T17:56:34.727751Z","shell.execute_reply":"2023-05-28T17:56:34.727777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image1 = Image.open(\"/kaggle/working/ships/train/submarine_scaled/2567.jpg\")\nimage2 = Image.open(\"/kaggle/input/navires-2023-la-mano/ships16x24/ships_16x24_10cat/data/submarine_scaled/2567.jpg\")\nimage3 = Image.open(\"/kaggle/working/ships/train/submarine_scaled/augmented_0_2567.jpg\")\n\nfig, axes = plt.subplots(1, 3, figsize=(10, 5))\naxes[0].imshow(image2) \naxes[0].axis('off')\naxes[0].set_title('Image Originale')\n\naxes[1].imshow(image1) \naxes[1].axis('off')\naxes[1].set_title('Image Agrandi')\n\naxes[2].imshow(image3) \naxes[2].axis('off')\naxes[2].set_title('Variations de limage')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.729617Z","iopub.status.idle":"2023-05-28T17:56:34.730621Z","shell.execute_reply.started":"2023-05-28T17:56:34.730290Z","shell.execute_reply":"2023-05-28T17:56:34.730325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Création de notre modèle","metadata":{}},{"cell_type":"code","source":"# Affichage du nombre de couches\nmodel = Sequential()\n\n#model.add(Input(shape=(16,24,3)))\n\n#model.add(Rescaling(1./255))\nmodel.add(Resizing(64,96))\n\n# model.add(Rescaling(1./255))\n# model.add(Resizing(160,240))\n\n# Bloc 1\nmodel.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(64, 96, 3)))\nmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\n\nmodel.add(BatchNormalization())\n\n# Bloc 2\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\nmodel.add(BatchNormalization())\n\nmodel.add(Dropout(0.25))\n\n# Bloc 3\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\nmodel.add(BatchNormalization())\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.build((None, 64, 96, 3))\n\nprint(\"Nombre de couches :\", len(model.layers))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.732580Z","iopub.status.idle":"2023-05-28T17:56:34.733097Z","shell.execute_reply.started":"2023-05-28T17:56:34.732821Z","shell.execute_reply":"2023-05-28T17:56:34.732846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Entrainement du réseau","metadata":{}},{"cell_type":"code","source":"# Paramètres d'entraînement\nbatch_size = 64\nepochs = 25\n\n# Générateurs de données\ntrain_datagen = ImageDataGenerator(\n    validation_split=0.2, \n    rotation_range = 10,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    rescale=1./250, \n    vertical_flip=True)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(16,24), color_mode=\"rgb\", shuffle = True, batch_size=batch_size, class_mode='categorical')\nval_generator = train_datagen.flow_from_directory(val_dir, target_size=(16,24), batch_size=batch_size, class_mode='categorical')\n\n# Compilation et entraînement du modèle\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.735232Z","iopub.status.idle":"2023-05-28T17:56:34.736361Z","shell.execute_reply.started":"2023-05-28T17:56:34.736025Z","shell.execute_reply":"2023-05-28T17:56:34.736066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, steps_per_epoch=train_generator.n//batch_size, epochs=epochs, validation_data=val_generator, validation_steps=val_generator.n//batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.738146Z","iopub.status.idle":"2023-05-28T17:56:34.738668Z","shell.execute_reply.started":"2023-05-28T17:56:34.738392Z","shell.execute_reply":"2023-05-28T17:56:34.738418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Courbe de la perte\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss')\nplt.legend()\n\n# Courbe de l'exactitude\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.740256Z","iopub.status.idle":"2023-05-28T17:56:34.741358Z","shell.execute_reply.started":"2023-05-28T17:56:34.741024Z","shell.execute_reply":"2023-05-28T17:56:34.741064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La matrice de confusion est une matrice carrée qui représente la performance d'un modèle de classification. Elle est composée de différentes valeurs qui indiquent le nombre de prédictions correctes et incorrectes effectuées par le modèle pour chaque classe.\nLes valeurs diagonales de la matrice représentent les prédictions correctes pour chaque classe. Plus ces valeurs sont élevées, meilleure est la performance du modèle.\nLes valeurs non diagonales de la matrice représentent les prédictions incorrectes. Elles indiquent combien de fois le modèle a confondu une classe avec une autre.\nEn analysant les valeurs de la matrice de confusion, on peut déduire des informations sur les performances du modèle, telles que les classes les plus difficiles à prédire ou les confusions les plus fréquentes entre les classes.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Obtenir les prédictions pour le jeu de validation\npredictions = model.predict(val_generator)\npredicted_labels = np.argmax(predictions, axis=1)\n\n# Obtenir les étiquettes réelles du jeu de validation\ntrue_labels = val_generator.labels\n\n# Créer la matrice de confusion\nconfusion_matrix = confusion_matrix(true_labels, predicted_labels)\n\n# Afficher la matrice de confusion\nprint(\"Matrice de confusion :\")\nprint(confusion_matrix)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.743218Z","iopub.status.idle":"2023-05-28T17:56:34.743745Z","shell.execute_reply.started":"2023-05-28T17:56:34.743477Z","shell.execute_reply":"2023-05-28T17:56:34.743504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Charger les données du fichier \"test.npy\"\ndata = np.load(\"/kaggle/input/navires-2023-la-mano/test.npy\")\nprint(data.shape)\n\n# Normaliser les données\nnormalized_data = data / 250.0\n\n# Prédire les étiquettes\npredictions = model.predict(normalized_data)\n\npredicted_labels = np.argmax(predictions, axis=1)\nprint(predictions.shape)\n\nresults_df = pd.DataFrame({'Id': range(0, len(predicted_labels)), 'Category': predicted_labels})\nprint(results_df)\n\nresults_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.745328Z","iopub.status.idle":"2023-05-28T17:56:34.746464Z","shell.execute_reply.started":"2023-05-28T17:56:34.746115Z","shell.execute_reply":"2023-05-28T17:56:34.746156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#res = model.predict(np.load(\"/kaggle/input/navires-2023-la-mano/test.npy\")).argmax(axis=1)\n#df = pd.DataFrame({\"Category\":res})\n#df.to_csv(\"submission.csv\", index_label=\"Id\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.749987Z","iopub.status.idle":"2023-05-28T17:56:34.750520Z","shell.execute_reply.started":"2023-05-28T17:56:34.750234Z","shell.execute_reply":"2023-05-28T17:56:34.750260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-28T17:56:34.752451Z","iopub.status.idle":"2023-05-28T17:56:34.753454Z","shell.execute_reply.started":"2023-05-28T17:56:34.753146Z","shell.execute_reply":"2023-05-28T17:56:34.753181Z"},"trusted":true},"execution_count":null,"outputs":[]}]}